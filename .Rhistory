"entrezB",
"score",
"details"), col_types = "ccccnc")
hippie.db
?read_tsv
hippie.db <- read_tsv("hippie_v2.1.txt", quote = "", col_names = c("uniprotA",
"entrezA",
"uniprotB",
"entrezB",
"score",
"details"), col_types = "ccccdc")
hippie.db
vignette("column-types")
hippie.db <- read_tsv("hippie_v2.1.txt", quote = "",
col.names = c("uniprotA", "entrezA",
"uniprotB", "entrezB", "score", "details"),
col_types = "ccccdc")
hippie.db <- read_tsv("hippie_v2.1.txt", quote = "",
col_names = c("uniprotA", "entrezA",
"uniprotB", "entrezB", "score", "details"),
col_types = "ccccdc")
hippie.db <- select(hippie.db, entrezA, entrezB, score, details)
hippie.db <- read_tsv("hippie_v2.1.txt", quote = "",
col_names = c("uniprotA", "entrezA",
"uniprotB", "entrezB", "score", "details"),
col_types = "ccccdc")
#Keep only useful information
hippie.db <- select(hippie.db, entrezA, entrezB, score, details)
#Weights will correspond to number of PMIDs reporting each interaction
pmids <- sapply(strsplit(hippie.db$details, ";"), function(x) x[2])
hippie.db <- mutate(hippie.db, weight =
sapply(strsplit(pmids, ","), function(x) length(x)))
hippie.db <- select(hippie.db, entrezA, entrezB, weight, score)
hippie.db
library(igraph)
load("~/Desktop/hippie2igraph/hPIN_complete.RData")
vcount(pin)
ecount(pin)
sum(duplicated(V(pin)$name))
sum(V(pin)$name = "")
sum(V(pin)$name == "")
transitivity(pin, "average")
fit_power_law(degree(pin))$alpha
library(NetHypGeom)
plot_degree_distr(pin)
plot_degree_distr(network = pin)
d <- degree(pin, mode = "all")
min(d)
max(d)
log10(0)
pin <- delete_vertices(pin, v = which(degree(pin) < 1))
is_simple(pin)
is_connected(pin)
sum(duplicated(V(pin)$name))
sum(V(pin)$name == "")
plot_degree_distr(network = pin)
plot_degree_distr(network = pin, bins = 50)
plot_degree_distr(network = pin, bins = 200)
plot_degree_distr(network = pin, bins = 300)
plot_degree_distr(network = pin, bins = 500)
plot_degree_distr(network = pin, bins = 1000)
plot_degree_distr(network = pin, bins = 500)
plot_degree_distr(network = pin, bins = 1000)
plot_degree_distr(network = pin, bins = 5000)
transitivity(pin, "average")
fit_power_law(degree(pin))$alpha
min(degree(pin))
vcount(pin)
16669 - 16642
min(E(pin)$weight)
max(E(pin)$weight)
max(E(pin)$score)
min(E(pin)$score)
save(pin, file = "hPIN_complete.RData")
load("~/Desktop/hippie2igraph/hPIN_150k.RData")
library(igraph)
library(igraph)
g <- sample_pa(10, power = 0.3)
plot(g)
g <- sample_pa(10, power = 0.3, directed = F)
plot(g)
V(g)$name
V(g)$name <- letters[1:10]
plot(g)
E(g)["f" %--% "i"]
tmp <- E(g)["f" %--% "i"]
tmp
tmp$score
ecount(g)
E(g)$score <- runif(9)
plot(g)
E(g)["a" %--% "b"]
tmp <- E(g)["a" %--% "b"]
tmp$score
tmp <- E(g)[c("a", "a", "a") %--% c("b", "g", "h")]
tmp
tmp$score
setwd("../Projects/ppi_disparity/")
load("results/hippie_disp_analysis.RData")
rm(disp.analysis, node.disp, p.disp.filter, p.node.disp)
alpha <- cut(edge.pvals, breaks = 5, include.lowest = T)
levels(alpha)
min(edge.pvals)
max(edge.pvals)
load("data/hippie_v2.RData")
edg <- as_data_frame(pin, what = "edges")
head(edg)
head(rep(edg$from, each = 2))
head(rep(edg$to, each = 2))
head(alpha)
alpha <- cut(edge.pvals, breaks = 5)
levels(alpha)
load("data/hippie_v2.RData")
load("results/hippie_disp_analysis.RData")
rm(disp.analysis, node.disp, p.disp.filter, p.node.disp)
library(dplyr)
edg <- as_data_frame(pin, what = "edges") %>% select(from, to)
edg <- igraph::as_data_frame(pin, what = "edges") %>% select(from, to)
alpha <- cut(edge.pvals, breaks = 5, include.lowest = T)
df <- tibble(a = rep(edg$from, each = 2), b = rep(edg$to, each = 2),
alpha = rep(alpha, each = 2), score = numeric(nrow(edg)*2),
db = factor(rep(c("HIPPIE", "STRING"), times = nrow(edg))))
df
df$score <- runif(653516)
ggplot(df, aes(alpha, score, colour = db)) +
geom_boxplot(width = 0.5) +
labs(x = expression(alpha), y = "Confidence score") + theme_bw() +
theme(legend.title = element_blank(), legend.background = element_blank(),
legend.justification = c(1,1), legend.position = c(1,1))
library(ggplot2)
ggplot(df, aes(alpha, score, colour = db)) +
geom_boxplot(width = 0.5) +
labs(x = expression(alpha), y = "Confidence score") + theme_bw() +
theme(legend.title = element_blank(), legend.background = element_blank(),
legend.justification = c(1,1), legend.position = c(1,1))
df
ggplot(df, aes(alpha, score, colour = db)) +
geom_boxplot() +
labs(x = expression(alpha), y = "Confidence score") + theme_bw() +
theme(legend.title = element_blank(), legend.background = element_blank(),
legend.justification = c(1,1), legend.position = c(1,1))
ggplot(df, aes(alpha, score, fill = db)) +
geom_boxplot(width = 0.4) +
labs(x = expression(alpha), y = "Confidence score") + theme_bw() +
theme(legend.title = element_blank(), legend.background = element_blank(),
legend.justification = c(1,1), legend.position = c(1,1))
ggplot(df, aes(alpha, score, fill = db)) +
geom_boxplot(width = 0.5) +
labs(x = expression(alpha), y = "Confidence score") + theme_bw() +
theme(legend.title = element_blank(), legend.background = element_blank(),
legend.justification = c(1,1), legend.position = c(1,1))
setwd("~/Desktop/titanic_rf/")
library(readr)
library(dplyr)
# Recursive Partitioning and Regression Trees, part of Base R
library(rpart)
# Need to be installed
library(rattle) # Do sudo apt-get install libgtk2.0-dev before installation
library(rpart.plot)
library(RColorBrewer)
# Import data ------------------------------------------------
train <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
# Decision tree with default parameters -----------------------------------
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,
data = train,
method = "class")
# Base R visualisation
plot(fit)
text(fit)
# Fancy visualisation
fancyRpartPlot(fit)
fit <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,
data = train,
method = "class",
control = rpart.control(minsplit = 2, cp = 0))
pred <- predict(fit, test, type = "class")
submission <- select(test, PassengerId) %>% mutate(Survived = pred)
write_csv(submission, path = "results/dec_tree_overfit.csv")
library(readr)
library(dplyr)
# Recursive Partitioning and Regression Trees, part of Base R
library(rpart)
# Need to be installed
library(rattle) # Do sudo apt-get install libgtk2.0-dev before installation
library(rpart.plot)
library(RColorBrewer)
# Import data ------------------------------------------------
train <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
library(tidyr)
train
test <- mutate(test, Survived = NA)
combi <- rbind(train, test)
combi <- separate(combi, Name, into = c("LName", "Title", "FName"),
sep = "[,.]")
combi
unique(combi$Title)
table(combi$Title)
library(stringr)
str_view(train$Name[1], "[,.]")
str_view_all(train$Name[1], "[,.]")
str_view_all(train$Name[1], "[,\.]")
str_view_all(train$Name[1], "[,\\.]")
str_view(train$Name[1], "[,\\.]")
combi <- rbind(train, test)
combi <- separate(combi, Name, into = c("LName", "Title", "FName"),
sep = "[,\\.]")
table(combi$Title)
str_count(train$Name[1], "[,\\.]")
str_count(train$Name[1], "[,.]")
str_count(train$Name[1], "[.]")
str_count(train$Name[1], "[,]")
str_count(train$Name[1], "[.,]")
str_view(train$Name[1], "[,\\.]")
str_view_all(train$Name[1], "[,\\.]")
str_view_all(train$Name[1], "[,.]")
test <- mutate(test, Survived = NA)
combi <- rbind(train, test)
# Let's see if name titles help with prediction of survival
combi <- separate(combi, Name, into = c("LName", "Title", "FName"),
sep = "[,.]")
train$Name
table(combi$Title)
combi <- mutate(Title = replace(Title, Title %in% c("Mme", "Mlle"), "Mlle"))
combi <- mutate(Title = replace(Title, Title %in%
c("Capt", "Don", "Major", "Sir"), "Sir"))
combi <- mutate(Title = replace(Title, Title %in%
c("Dona", "Lady", "the Countess", "Jonkheer"),
"Lady"))
combi <- mutate(combi, Title = replace(Title,
Title %in% c("Mme", "Mlle"), "Mlle"))
combi <- mutate(combi, Title = replace(Title,
Title %in% c("Capt", "Don", "Major", "Sir"),
"Sir"))
combi <- mutate(combi, Title = replace(Title,
Title %in% c("Dona", "Lady", "the Countess",
"Jonkheer"),
"Lady"))
combi <- mutate(combi, FamilySize = SibSp + Parch + 1)
combi <- mutate(combi, FamilyID = paste0(FamilySize, LName))
combi <- mutate(combi, FamilyID = replace(FamilyID, FamilySize <= 2, "Small"))
table(combi$FamilyID)
combi <- mutate(combi, FamilyID = paste0(FamilySize, LName))
combi
combi %>% select(FName, LName, FamilySize, FamilyID)
combi %>% select(FName, LName, FamilySize, FamilyID) %>% arrange(LName)
combi %>% select(FName, LName, FamilySize, FamilyID) %>% arrange(LName) %>% print(n = 20)
combi %>% select(FName, LName, FamilySize, FamilyID) %>% arrange(LName) %>% print(n = 50)
combi <- mutate(combi, FamilyID = replace(FamilyID, FamilySize <= 2, "Small"))
table(combi$FamilyID)
table(combi$FamilyID) <= 2
names(table(combi$FamilyID) <= 2)
combi <- mutate(combi, FamilyID = replace(FamilyID,
FamilyID %in%
names(table(combi$FamilyID) <= 2),
"Small"))
# Transform Title and FamilyID into factors
combi$Title <- as.factor(combi$Title)
combi$FamilyID <- as.factor(combi$FamilyID)
table(combi$FamilyID)
combi <- mutate(combi, FamilyID = replace(FamilyID, FamilySize <= 2, "Small"))
famID <- tibble(table(combi$FamilyID))
famId
famID
famID <- data.frame(table(combi$FamilyID))
famId
famID
combi <- mutate(combi, FamilyID = paste0(FamilySize, LName))
combi <- mutate(combi, FamilyID = replace(FamilyID, FamilySize <= 2, "Small"))
famID <- data.frame(table(combi$FamilyID))
famId
famID
tibble(table(combi$FamilyID))
table(combi$FamilyID)
combi %>% group_by(FamilyID) %>% summarise(Freq = count(FamilyID))
combi %>% group_by(FamilyID) %>% summarise(Freq = n())
combi %>% group_by(FamilyID) %>% count(FamilyID)
combi %>% group_by(FamilyID) %>% mutate(Freq = n())
combi %>% group_by(FamilyID) %>% mutate(Freq = n()) %>% select(FName, LName, FamilySize, FamilyID)
combi %>% group_by(FamilyID) %>% mutate(Freq = n()) %>% select(FName, LName, FamilySize, FamilyID, Freq)
combi %>% group_by(FamilyID) %>% mutate(Freq = n()) %>% select(FName, LName, FamilySize, FamilyID, Freq) %>% arrange(LName)
combi %>% group_by(FamilyID) %>% mutate(Freq = n()) %>% select(FName, LName, FamilySize, FamilyID, Freq) %>% arrange(LName) %>% print(20)
combi %>% group_by(FamilyID) %>% mutate(Freq = n()) %>% select(FName, LName, FamilySize, FamilyID, Freq) %>% arrange(LName) %>% print(n = 20)
table(combi$FamilyID)
combi <- group_by(combi, FamilyID) %>%
mutate(Freq = n()) %>%
mutate(FamilyID = replace(FamilyID, Freq <= 2, "Small"))
combi <- group_by(combi, FamilyID) %>%
mutate(Freq = n()) %>% ungroup() %>%
mutate(FamilyID = replace(FamilyID, Freq <= 2, "Small"))
table(combi$FamilyID)
combi$Title <- as.factor(combi$Title)
combi$FamilyID <- as.factor(combi$FamilyID)
train_fe <- filter(combi, !is.na(Survived))
test_fe <- filter(combi, is.na(Survived))
fit <- rpart(Survived ~ Pclass + Sex + Age +
SibSp + Parch + Fare + Embarked +
Title + FamilySize + FamilyID,
data = train, method = "class")
train_fe
fit <- rpart(Survived ~ Pclass + Sex + Age +
SibSp + Parch + Fare + Embarked +
Title + FamilySize + FamilyID,
data = train_fe, method = "class")
fancyRpartPlot(fit)
train <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
# Feature engineering -----------------------------------------------------
# Combine the train and test sets to obtain all engineered features for
# both cases
test <- mutate(test, Survived = NA)
combi <- rbind(train, test)
# Let's see if name titles help with prediction of survival
combi <- separate(combi, Name, into = c("LName", "Title", "FName"),
sep = "[,.]")
# Group redundant titles into more general ones
combi <- mutate(combi, Title = replace(Title,
Title %in% c("Mme", "Mlle"), "Mlle"))
combi <- mutate(combi, Title = replace(Title,
Title %in% c("Capt", "Don", "Major", "Sir"),
"Sir"))
combi <- mutate(combi, Title = replace(Title,
Title %in% c("Dona", "Lady", "the Countess",
"Jonkheer"),
"Lady"))
# Big families could have had troubles surviving, so let's sum number of
# siblings/spouses, parents/children and add the passenger himself
combi <- mutate(combi, FamilySize = SibSp + Parch + 1)
# Maybe specific families had more troubles to survive than others, let's create
# a family ID by combining Surnames and family size
combi <- mutate(combi, FamilyID = paste0(FamilySize, LName))
# Given the hypothesis that large families might have had trouble sticking
# together in the panic, let's knock out any family size of two or less and
# call it a 'small' family
combi <- mutate(combi, FamilyID = replace(FamilyID, FamilySize <= 2, "Small"))
# If we explore the data with table(combi$FamilyID), we see cases like family
# '3Beckwith', which is supposed to have 3 members, but only has 2 in our data:
table(combi$FamilyID)
# To solve this problem, we label family IDs with frequencies below 3 as "small"
combi <- group_by(combi, FamilyID) %>%
mutate(Freq = n()) %>% ungroup() %>%
mutate(FamilyID = replace(FamilyID, Freq <= 2, "Small"))
# Transform Title and FamilyID into factors
combi$Title <- as.factor(combi$Title)
combi$FamilyID <- as.factor(combi$FamilyID)
# Let's get back to train and test sets with engineered features
train_fe <- filter(combi, !is.na(Survived))
test_fe <- filter(combi, is.na(Survived))
fit <- rpart(Survived ~ Pclass + Sex + Age +
SibSp + Parch + Fare + Embarked +
Title + FamilySize + FamilyID,
data = train_fe, method = "class")
fancyRpartPlot(fit)
table(train_fe$Title)
sum(Title %in% c("Mme", "Mlle"))
sum(combi$Title %in% c("Mme", "Mlle"))
sum(train_fe$Title %in% c("Mme", "Mlle"))
sum(train_fe$Title %in% c(" Mme", " Mlle"))
?trimws()
combi <- separate(combi, Name, into = c("LName", "Title", "FName"),
sep = "[,.]")
combi <- mutate(combi, Title = trimws(Title),
LName = trimws(LName),
FName = trimws(FName))
combi <- rbind(train, test)
combi <- separate(combi, Name, into = c("LName", "Title", "FName"),
sep = "[,.]")
combi <- mutate(combi, Title = trimws(Title),
LName = trimws(LName),
FName = trimws(FName))
combi <- mutate(combi, Title = replace(Title,
Title %in% c("Mme", "Mlle"), "Mlle"))
combi <- mutate(combi, Title = replace(Title,
Title %in% c("Capt", "Don", "Major", "Sir"),
"Sir"))
combi <- mutate(combi, Title = replace(Title,
Title %in% c("Dona", "Lady", "the Countess",
"Jonkheer"),
"Lady"))
combi <- mutate(combi, FamilySize = SibSp + Parch + 1)
# Maybe specific families had more troubles to survive than others, let's create
# a family ID by combining Surnames and family size
combi <- mutate(combi, FamilyID = paste0(FamilySize, LName))
# Given the hypothesis that large families might have had trouble sticking
# together in the panic, let's knock out any family size of two or less and
# call it a 'small' family
combi <- mutate(combi, FamilyID = replace(FamilyID, FamilySize <= 2, "Small"))
# If we explore the data with table(combi$FamilyID), we see cases like family
# '3Beckwith', which is supposed to have 3 members, but only has 2 in our data:
table(combi$FamilyID)
# To solve this problem, we label family IDs with frequencies below 3 as "small"
combi <- group_by(combi, FamilyID) %>%
mutate(Freq = n()) %>% ungroup() %>%
mutate(FamilyID = replace(FamilyID, Freq <= 2, "Small"))
# Transform Title and FamilyID into factors
combi$Title <- as.factor(combi$Title)
combi$FamilyID <- as.factor(combi$FamilyID)
# Let's get back to train and test sets with engineered features
train_fe <- filter(combi, !is.na(Survived))
test_fe <- filter(combi, is.na(Survived))
fit <- rpart(Survived ~ Pclass + Sex + Age +
SibSp + Parch + Fare + Embarked +
Title + FamilySize + FamilyID,
data = train_fe, method = "class")
fancyRpartPlot(fit)
test_fe
test_fe <- select(test_fe, -Survived)
test_fe
pred <- predict(fit, test_fe, type = "class")
submission <- select(test_fe, PassengerId) %>% mutate(Survived = pred)
write_csv(submission, path = "results/dec_tree_feat_eng.csv")
save(combi, file = "data/combined_train_test.RData")
load("data/combined_train_test.RData")
library(readr)
library(dplyr)
library(tidyr)
# Recursive Partitioning and Regression Trees, part of Base R
library(rpart)
# Need to be installed
library(rattle) # Do sudo apt-get install libgtk2.0-dev before installation
library(rpart.plot)
library(RColorBrewer)
summary(combi$Age)
age_fit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare +
Embarked + Title + FamilySize,
data = combi[!is.na(combi$Age), ], # We train with aged samples
method = "anova")
combi <- mutate(combi, Age = replace(Age, is.na(Age),
predict(age_fit, combi[is.na(combi$Age), ])))
summary(combi$Age)
summary(combi$Embarked)
summary(factor(combi$Embarked))
summary(factor(combi$Embarked))
combi <- mutate(combi, Embarked = replace(Embarked, is.na(Embarked), "S"))
summary(factor(combi$Embarked))
summary(combi$Fare)
combi <- mutate(combi, Fare = replace(Fare, is.na(Fare), median(Fare)))
summary(combi$Fare)
median(combi$Fare)
median(combi$Fare, na.rm = T)
combi <- mutate(combi, Fare = replace(Fare, is.na(Fare), median(Farem, na.rm = T)))
combi <- mutate(combi, Fare = replace(Fare, is.na(Fare), median(Fare, na.rm = T)))
summary(combi$Fare)
length(levels(combi$FamilyID))
combi <- mutate(combi, FamilyID2 = as.character(FamilyID)) %>%
mutate(FamilyID2 = as.factor(replace(FamilyID2, FamilySize <= 3, "Small")))
length(levels(combi$FamilyID2))
library(randomForest)
set.seed(415)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp
+ Parch + Fare + Embarked + Title +
FamilySize + FamilyID2,
data = train,
importance = TRUE, # Compute feature importance?
ntree = 2000) # Number of trees in the forest
train <- filter(combi, !is.na(Survived))
test <- filter(combi, is.na(Survived))
test <- select(test, -Survived)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp
+ Parch + Fare + Embarked + Title +
FamilySize + FamilyID2,
data = train,
importance = TRUE, # Compute feature importance?
ntree = 2000) # Number of trees in the forest
summary(combi)
summary(train)
summary(test)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Parch + Fare + Embarked + Title +
FamilySize + FamilyID2,
data = train,
importance = TRUE, # Compute feature importance?
ntree = 2000) # Number of trees in the forest
combi$Embarked <- as.factor(combi$Embarked)
summary(test)
combi
combi$Embarked <- factor(combi$Embarked)
summary(test)
summary(combi)
combi$Sex <- as.factor(combi$Sex)
train <- filter(combi, !is.na(Survived))
test <- filter(combi, is.na(Survived))
test <- select(test, -Survived)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp +
Parch + Fare + Embarked + Title +
FamilySize + FamilyID2,
data = train,
importance = TRUE, # Compute feature importance?
ntree = 2000) # Number of trees in the forest
varImpPlot(fit)
pred <- predict(fit, test, type = "class")
submission <- select(test, PassengerId) %>% mutate(Survived = pred)
write_csv(submission, path = "results/random_forest.csv")
install.packages(party)
install.packages("party")
save(combi, file = "data/combined_train_test_imputed.RData")
library(dplyr)
library(party)
load("data/combined_train_test_imputed.RData")
train <- filter(combi, !is.na(Survived))
test <- filter(combi, is.na(Survived))
test <- select(test, -Survived)
set.seed(415)
fit <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare +
Embarked + Title + FamilySize + FamilyID,
data = train,
controls = cforest_unbiased(ntree = 2000, # Number of trees
mtry = 3)) # Features to sample
pred <- predict(fit, test, OOB=TRUE, type = "response")
submission <- select(test, PassengerId) %>% mutate(Survived = pred)
write_csv(submission, path = "results/forest_cond_inf_trees.csv")
